{"cells":[{"cell_type":"markdown","metadata":{"id":"YnldQj6j38cP"},"source":["# Load Datasets"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18022,"status":"ok","timestamp":1750644460434,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"2EsGHBhlWK0l","outputId":"8d50701d-e394-4c98-d166-046457575881"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import json\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1779,"status":"ok","timestamp":1750644462211,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"PsQP-SzxWOCX"},"outputs":[],"source":["with open(\"/content/drive/My Drive/sharded_dataset.json\") as f:\n","  data = json.load(f)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1750644462236,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"gmB_2ey5wVmO"},"outputs":[],"source":["D2T = []\n","Code = []\n","GSM8K = []\n","DB = []\n","API = []\n","for task in data:\n","  if \"code\" in task['task']:\n","    Code.append(task)\n","  if \"math\" in task['task']:\n","    GSM8K.append(task)\n","  if \"database\" in task['task']:\n","    DB.append(task)\n","  if \"actions\" in task['task']:\n","    API.append(task)\n","  if \"data2text\" in task['task']:\n","    D2T.append(task)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAyAYfuS0BLw"},"outputs":[],"source":["import tiktoken\n","def count_tokens(text: str, model: str = \"gpt-4\"):\n","    encoding = tiktoken.encoding_for_model(model)\n","    tokens = encoding.encode(text)\n","    return len(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-A3H3GXwA94F"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/Context_reset/MATH/MATH_GPT4o/GSM8K_run0_CORRECTED.json\", 'r') as f:\n","  data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbH_LkCIzxiZ"},"outputs":[],"source":["tokens = []\n","\n","for i, entry in enumerate(data):\n","  t = []\n","  tk = 0\n","  if entry['resets'] == 0:\n","    for i, msg in enumerate(entry['chat_history']):\n","      if msg['role'] == 'user':\n","        tk += count_tokens(msg['content'])\n","        t.append(tk)\n","      elif msg['role'] == 'assistant':\n","        tk += count_tokens(msg['content'])\n","      elif msg['role'] == 'system':\n","        tk += count_tokens(msg['content'])\n","    tokens.append(np.mean(t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A59vnAXJ2dLR"},"outputs":[],"source":["import ast\n","token_res = []\n","for i, entry in enumerate(data):\n","  t = []\n","  tk = 0\n","  if entry['resets'] == 1:\n","    parts = entry['chat_history'].split(\"AFTER RESET\")\n","    list1 = ast.literal_eval(parts[0].strip())\n","    list2 = ast.literal_eval(parts[1].strip())\n","    for msg in list1:\n","      if msg['role'] == 'user':\n","        tk += count_tokens(msg['content'])\n","        t.append(tk)\n","      elif msg['role'] == 'assistant':\n","        tk += count_tokens(msg['content'])\n","      elif msg['role'] == 'system':\n","        tk += count_tokens(msg['content'])\n","    tk = 0\n","    for msg in list2:\n","      if msg['role'] == 'user':\n","        tk += count_tokens(msg['content'])\n","        t.append(tk)\n","      elif msg['role'] == 'assistant':\n","        tk += count_tokens(msg['content'])\n","      elif msg['role'] == 'system':\n","        tk += count_tokens(msg['content'])\n","    token_res.append(np.mean(t))"]},{"cell_type":"markdown","metadata":{"id":"3VGX8_24acA-"},"source":["#Utility Functions"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1750644598607,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"QoeP_02ebPul","outputId":"11191841-5a25-4479-96bf-00479aba683f"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-06-23 02:09:58--  https://raw.githubusercontent.com/microsoft/lost_in_conversation/main/tasks/actions/eval_bfcl.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 31177 (30K) [text/plain]\n","Saving to: ‘eval_bfcl.py.1’\n","\n","\reval_bfcl.py.1        0%[                    ]       0  --.-KB/s               \reval_bfcl.py.1      100%[===================>]  30.45K  --.-KB/s    in 0.01s   \n","\n","2025-06-23 02:09:58 (2.87 MB/s) - ‘eval_bfcl.py.1’ saved [31177/31177]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/microsoft/lost_in_conversation/main/tasks/actions/eval_bfcl.py"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1750644598676,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"1PD7t6x6bbZx","outputId":"bd53514e-8955-4526-a7e2-218986287007"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-06-23 02:09:58--  https://raw.githubusercontent.com/microsoft/lost_in_conversation/main/tasks/actions/task_actions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3605 (3.5K) [text/plain]\n","Saving to: ‘task_actions.py.1’\n","\n","\rtask_actions.py.1     0%[                    ]       0  --.-KB/s               \rtask_actions.py.1   100%[===================>]   3.52K  --.-KB/s    in 0s      \n","\n","2025-06-23 02:09:58 (29.6 MB/s) - ‘task_actions.py.1’ saved [3605/3605]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/microsoft/lost_in_conversation/main/tasks/actions/task_actions.py"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6638,"status":"ok","timestamp":1750644605382,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"Cja0D938-mg7","outputId":"b8b30b0c-bea1-44e3-9793-7a4a71bc17d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"]}],"source":["pip install sacrebleu"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1750644605386,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"yOUanPR9-lxZ"},"outputs":[],"source":["import sacrebleu\n","def D2T_evaluator_function(extracted_answer, sample):\n","    # ToTTo has multiple references per example\n","    references = sample[\"references\"]\n","    bleu = sacrebleu.corpus_bleu([extracted_answer.strip()], [[ref.strip()] for ref in references])\n","    return bleu.score / 100.0"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1750644605387,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"FdgQjDLvbcre"},"outputs":[],"source":["from eval_bfcl import parallel_function_checker_enforce_order, parallel_function_checker_no_order, ast_checker, ast_parse"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1750644605387,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"BrYkyAUubd-E"},"outputs":[],"source":["import re\n","\n","def extract_function_block(text):\n","    start = text.find('[')\n","    if start == -1:\n","        return ''\n","\n","    level = 0\n","    for i in range(start, len(text)):\n","        if text[i] == '[':\n","            level += 1\n","        elif text[i] == ']':\n","            level -= 1\n","            if level == 0:\n","                block = text[start:i+1]\n","                return clean_function_block(block)\n","    return ''\n","\n","def clean_function_block(block):\n","    block = block.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n","    block = ' '.join(block.split())\n","\n","    # Remove \"...\" wrapping function calls only\n","    block = re.sub(r'\"\\s*([a-zA-Z_][a-zA-Z0-9_\\.]*\\s*\\([^\"]*\\))\\s*\"', r'\\1', block)\n","\n","    # Remove space after [ and before ]\n","    block = re.sub(r'\\[\\s+', '[', block)\n","    block = re.sub(r'\\s+\\]', ']', block)\n","\n","    return block\n","\n","\n","def extract_all_function_blocks(text):\n","    blocks = []\n","    start_positions = [i for i, c in enumerate(text) if c == '[']\n","\n","    for start in start_positions:\n","        level = 0\n","        found = False\n","        for i in range(start, len(text)):\n","            if text[i] == '[':\n","                level += 1\n","            elif text[i] == ']':\n","                level -= 1\n","                if level == 0:\n","                    block = text[start:i+1]\n","                    blocks.append(clean_function_block(block))\n","                    found = True\n","                    break\n","        if found:\n","            # Skip any nested [ inside this block — move to next outer [\n","            continue\n","    return blocks\n","\n","def evaluator_function(predicted_answer, sample):\n","    \"\"\"\n","    Evaluate if the predicted function call matches the expected format and functionality.\n","    \"\"\"\n","\n","    try:\n","        decoded_output = ast_parse(predicted_answer.strip(), sample[\"language\"])\n","    except Exception as e:\n","        # print(f\"\\033[94mPredicted answer:{predicted_answer}\\033[0m\")\n","        return {\"is_correct\": False, \"error\": \"Failing to parse the predicted answer as an AST\"}\n","\n","    result = ast_checker(\n","        sample[\"function\"],\n","        decoded_output,\n","        sample[\"reference_answer\"],\n","        sample[\"language\"],\n","        sample[\"test_category\"],\n","        \"gpt-4o\"\n","    )\n","    score = 1 if result[\"valid\"] else 0\n","    return {\"is_correct\": result[\"valid\"], \"score\": score, \"error\": result[\"error\"]}\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1750644605394,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"ajLrIxJ_alZc"},"outputs":[],"source":["import re\n","\n","def extract_sql_query(text):\n","    # Match content inside ```sql ... ``` block\n","    match = re.search(r'```sql(.*?)```', text, re.DOTALL | re.IGNORECASE)\n","    if match:\n","        # Clean leading/trailing whitespace\n","        return match.group(1).strip()\n","    else:\n","        return None\n","\n","\n","def extract_sql_queries(text):\n","    \"\"\"\n","    Extract all SQL queries from a text blob.\n","    Captures both fenced code blocks (```sql ... ```) and standalone statements ending with semicolons.\n","    \"\"\"\n","    queries = []\n","\n","    # 1) Fenced SQL blocks\n","    fenced = re.findall(r'```sql\\s*(.*?)```', text, flags=re.IGNORECASE | re.DOTALL)\n","    queries.extend(q.strip() for q in fenced if q.strip())\n","\n","    # 2) Standalone statements (SELECT/INSERT/UPDATE/DELETE/CREATE/ALTER/DROP) ending with ;\n","    #    Avoid re-capturing fenced blocks by skipping matches that span lines containing ```\n","    stmt_pattern = re.compile(\n","        r'(?:\\b(?:SELECT|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP)\\b.+?;)',\n","        flags=re.IGNORECASE | re.DOTALL\n","    )\n","    for m in stmt_pattern.finditer(text):\n","        snippet = m.group().strip()\n","        # skip if it's identical to a fenced block\n","        if not any(snippet == f.strip() or snippet in f for f in fenced):\n","            queries.append(snippet)\n","    # if not queries:\n","    #   queries.append(text)\n","    return queries"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1750644605409,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"ObclVGSLfO5D"},"outputs":[],"source":["import re\n","\n","def extract_all_function_blocks_and_names(code):\n","    \"\"\"\n","    Extracts all top-level Python function blocks (def ...) along with any import\n","    statements that appear immediately before each function. Returns a list of tuples:\n","    [(full_code_with_imports, function_name), ...].\n","    \"\"\"\n","    lines = code.strip().splitlines()\n","    n = len(lines)\n","    results = []\n","    import_lines = []\n","    i = 0\n","\n","    while i < n:\n","        line = lines[i]\n","\n","        # If this line is an import, collect it and move on\n","        if re.match(r'^\\s*import\\s+\\w', line) or re.match(r'^\\s*from\\s+\\w+\\s+import\\s+', line):\n","            import_lines.append(line)\n","            i += 1\n","            continue\n","\n","        # If this line is a top‐level function definition\n","        func_match = re.match(r'^(\\s*)def\\s+([A-Za-z_]\\w*)\\s*\\(.*\\)\\s*:', line)\n","        if func_match:\n","            func_indent = len(func_match.group(1))\n","            func_name = func_match.group(2)\n","\n","            # Collect the entire function block\n","            func_block = [lines[i]]\n","            j = i + 1\n","            while j < n:\n","                next_line = lines[j]\n","                # Blank lines inside the block are allowed\n","                if next_line.strip() == \"\":\n","                    func_block.append(next_line)\n","                    j += 1\n","                    continue\n","\n","                # Check indentation: if indent > func_indent, it's still inside\n","                indent_level = len(next_line) - len(next_line.lstrip())\n","                if indent_level > func_indent:\n","                    func_block.append(next_line)\n","                    j += 1\n","                else:\n","                    break\n","\n","            # Combine the imports collected so far with this function block\n","            full_code = \"\\n\".join(import_lines + [\"\"] + func_block).rstrip()\n","            results.append((full_code, func_name))\n","\n","            # Reset import_lines for the next function\n","            import_lines = []\n","            # Continue scanning from the line after this function block\n","            i = j\n","            continue\n","\n","        # Neither an import nor a function definition: move on\n","        i += 1\n","\n","    return results\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1750644605410,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"L_S03peNpOm9"},"outputs":[],"source":["import re\n","\n","def extract_first_function_block_and_name(code):\n","    \"\"\"\n","    Extracts the first top-level Python function (def ...) block and its name,\n","    along with any import statements above it.\n","    Returns the full function code (with imports) and function name.\n","    \"\"\"\n","    lines = code.strip().splitlines()\n","    import_lines = []\n","    func_start_idx = None\n","    func_indent = None\n","    func_name = None\n","\n","    # Collect top-level import statements before the function\n","    for i, line in enumerate(lines):\n","        if re.match(r'^\\s*import\\s+\\w', line) or re.match(r'^\\s*from\\s+\\w+\\s+import\\s+', line):\n","            import_lines.append(line)\n","        # elif re.match(r'^\\s*def\\s+[a-zA-Z_]\\w*\\s*\\(.*\\)\\s*:', line):\n","        #     func_start_idx = i\n","        #     match = re.match(r'^(\\s*)def\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\(', line)\n","        #     func_indent = len(match.group(1))\n","        #     func_name = match.group(2)\n","        #     break\n","        elif re.match(r'^\\s*def\\s+[a-zA-Z_]\\w*\\s*\\(.*\\)\\s*(->\\s*[^\\s:]+)?\\s*:', line):\n","            func_start_idx = i\n","            match = re.match(r'^(\\s*)def\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\(.*\\)\\s*(->\\s*[^\\s:]+)?\\s*:', line)\n","            func_indent = len(match.group(1))\n","            func_name = match.group(2)\n","            break\n","\n","    if func_start_idx is None:\n","        return None, None\n","\n","    # Collect lines in the function block\n","    func_lines = lines[func_start_idx:]\n","    collected = [func_lines[0]]\n","\n","    for line in func_lines[1:]:\n","        if line.strip() == \"\":\n","            collected.append(line)\n","        elif len(line) - len(line.lstrip()) >= func_indent + 1:\n","            collected.append(line)\n","        else:\n","            break\n","\n","    return \"\\n\".join(import_lines + [\"\"] + collected).rstrip(), func_name\n"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1750644605433,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"Dqydr7zj-5Jo"},"outputs":[],"source":["import json\n","import numpy as np\n","import sys\n","import tempfile\n","import subprocess\n","import importlib.util\n","import ast\n","\n","def run_function_and_check(func_name, user_code, test_cases):\n","    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False, mode=\"w\") as f:\n","        user_code_path = f.name\n","        f.write(\"import math\\n\")\n","        f.write(user_code)\n","\n","    # print(user_code)\n","    runner_code = f\"\"\"\n","import json\n","import sys\n","import ast\n","import math\n","import importlib.util\n","\n","spec = importlib.util.spec_from_file_location(\"tempmod\", \"{user_code_path}\")\n","tempmod = importlib.util.module_from_spec(spec)\n","spec.loader.exec_module(tempmod)\n","\n","failures = []\n","def parse_argument(line):\n","    line = line.strip()\n","    if line.startswith('\"') and line.endswith('\"'):\n","        return line[1:-1]  # Strip outer double quotes, treat as string\n","    try:\n","        return ast.literal_eval(line)\n","    except:\n","        return line  # fallback\n","\n","for idx, case in enumerate({test_cases}):\n","    input_lines = case[\"input\"].splitlines()\n","    args = [parse_argument(line) for line in input_lines]\n","\n","    try:\n","        expected = ast.literal_eval(case[\"output\"])\n","    except:\n","        expected = case[\"output\"]\n","\n","    if expected == \"true\" or expected == \"Yes\" or expected == \"yes\":\n","        expected = True\n","\n","    if expected == \"false\" or expected == \"No\" or expected == \"no\":\n","        expected = False\n","\n","    try:\n","        got = getattr(tempmod, \"{func_name}\")(*args)\n","    except Exception as e:\n","        failures.append(f\"{{args}} raised {{e!r}}\")\n","        continue\n","\n","    if got == \"Yes\" or got == \"yes\":\n","      got = True\n","    if got == \"No\" or got == \"no\":\n","      got = False\n","\n","    if got and got != expected:\n","        args = args.reverse()\n","        try:\n","          got = getattr(tempmod, \"{func_name}\")(*args)\n","        except Exception as e:\n","          failures.append(f\"{{args}} raised {{e!r}}\")\n","          continue\n","\n","        if got == \"Yes\" or got == \"yes\":\n","          got = True\n","        if got == \"No\" or got == \"no\":\n","          got = False\n","\n","        if got != expected:\n","          failures.append(f\"Test {{idx}} :- {{args}}: got={{got!r}}, expected={{expected!r}}\")\n","\n","if failures:\n","    print(json.dumps({{\"ok\": False, \"errors\": failures}}))\n","    sys.exit(1)\n","else:\n","    print(json.dumps({{\"ok\": True}}))\n","    sys.exit(0)\n","\"\"\"\n","\n","    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False, mode=\"w\") as f:\n","        runner_path = f.name\n","        f.write(runner_code)\n","\n","    try:\n","      result = subprocess.run(\n","          [sys.executable, runner_path],\n","          capture_output=True,\n","          text=True,\n","          timeout=3\n","      )\n","    except:\n","      print(\"TIMEOUT ERROR\")\n","      return False\n","\n","    # print(\"STDOUT:\", result.stdout.strip())\n","    # print(\"STDERR:\", result.stderr.strip())\n","\n","    if result.returncode == 0:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1750644605451,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"A2Vb7b-kIbBh"},"outputs":[],"source":["import re\n","\n","def L_extract_sections(text):\n","    pattern = r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>\"\n","    return re.findall(pattern, text, flags=re.DOTALL)\n","\n","def PHI_extract_sections(text):\n","    pattern = r\"<\\|im_start\\|>assistant<\\|im_sep\\|>(.*?)<\\|im_end\\|>\"\n","    return re.findall(pattern, text, flags=re.DOTALL)"]},{"cell_type":"markdown","metadata":{"id":"I1C8ebkE-q6s"},"source":["# Coding Evaluation"]},{"cell_type":"code","execution_count":152,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1750624716207,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"CIAP_Lx-aZRb"},"outputs":[],"source":["import numpy as np\n","def evaluate_human_eval(data_path, dataset, numruns, numQ):\n","    \"\"\"\n","    For each line in the HumanEval JSON, generate code, check it,\n","    add 'correct' key (True/False), and write to a new JSON file with _CORRECTED suffix.\n","    \"\"\"\n","\n","    finalcorr = []\n","    for i in range(numruns):\n","        correct = []\n","        res = []\n","        with open(data_path + f\"_run{i}.json\", \"r\") as f:\n","            output = json.load(f)\n","        for x in range(numQ):\n","            final_output = output[x]['final_output']\n","            function, func_name = extract_first_function_block_and_name(final_output)\n","            test_cases = ast.literal_eval(dataset[x][\"public_test_cases\"])\n","\n","            if function and func_name:\n","                passed = run_function_and_check(func_name, function, test_cases)\n","                if passed:\n","                    correct.append(1)\n","                    output[x]['correct'] = True\n","            else:\n","              passed = False\n","            if not passed:\n","                for function in extract_all_function_blocks_and_names(output[x]['chat_history']):\n","                    passed = run_function_and_check(function[1], function[0], test_cases)\n","                    if passed:\n","                        correct.append(1)\n","                        output[x]['correct'] = True\n","                        break\n","                if not passed:\n","                    correct.append(0)\n","                    output[x]['correct'] = False\n","\n","\n","            res.append(output[x][\"resets\"])\n","        with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(output, f_out, indent=2)\n","\n","        finalcorr.append(correct)\n","\n","    sums = 0\n","    for i in range(len(finalcorr)):\n","      print(f\"Run {i} Score: {np.sum(finalcorr[i])/numQ}\")\n","      sums += np.sum(finalcorr[i]) / numQ\n","\n","    print(f\"Average {sums / len(finalcorr)}\")\n","\n","    return finalcorr\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXGNYe7IHQCd"},"outputs":[],"source":["import numpy as np\n","def GPT_evaluate_human_eval(data_path, dataset, numruns, numQ):\n","    \"\"\"\n","    For each line in the HumanEval JSON, generate code, check it,\n","    add 'correct' key (True/False), and write to a new JSON file with _CORRECTED suffix.\n","    \"\"\"\n","\n","    finalcorr = []\n","    for i in range(numruns):\n","        correct = []\n","        res = []\n","        with open(data_path + f\"_run{i}.json\", \"r\") as f:\n","            output = json.load(f)\n","        for x in range(numQ):\n","            final_output = output[x]['final_output']\n","            function, func_name = extract_first_function_block_and_name(final_output)\n","            test_cases = ast.literal_eval(dataset[x][\"public_test_cases\"])\n","\n","            if function and func_name:\n","                passed = run_function_and_check(func_name, function, test_cases)\n","                if passed:\n","                    correct.append(1)\n","                    output[x]['correct'] = True\n","            else:\n","              passed = False\n","\n","            if not passed:\n","                if output[x][\"resets\"] > 0:\n","                  for function in extract_all_function_blocks_and_names(output[x]['chat_history']):\n","                      passed = run_function_and_check(function[1], function[0], test_cases)\n","                      if passed:\n","                          correct.append(1)\n","                          output[x]['correct'] = True\n","                          break\n","                  if not passed:\n","                      correct.append(0)\n","                      output[x]['correct'] = False\n","                else:\n","                  for entry in output[x]['chat_history']:\n","                      if entry[\"role\"] == \"assistant\":\n","                        function, func_name = extract_first_function_block_and_name(entry['content'])\n","                        if function and func_name:\n","                          passed = run_function_and_check(func_name, function, test_cases)\n","                          if passed:\n","                              correct.append(1)\n","                              output[x]['correct'] = True\n","                              break\n","                  if not passed:\n","                      correct.append(0)\n","                      output[x]['correct'] = False\n","\n","            res.append(output[x][\"resets\"])\n","        with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(output, f_out, indent=2)\n","\n","        finalcorr.append(correct)\n","\n","    sums = 0\n","    for i in range(len(finalcorr)):\n","      print(f\"Run {i} Score: {np.sum(finalcorr[i])/numQ}\")\n","      sums += np.sum(finalcorr[i]) / numQ\n","\n","    print(f\"Average {sums / len(finalcorr)}\")\n","\n","    return finalcorr\n"]},{"cell_type":"markdown","metadata":{"id":"6flae93qa4GF"},"source":["# GSM8K Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23rVP0UUsy23"},"outputs":[],"source":["import json\n","import re\n","\n","def GPT_Eval_GSM8K(numruns, data_path, numQ=50, dataset=GSM8K):\n","    correct = []\n","    for x in range(numruns):\n","        corr = []\n","        with open(data_path + f\"_run{x}.json\", 'r') as f:\n","            NRoutput = json.load(f)\n","\n","        for i in range(numQ):\n","            answer = re.findall(r'####\\s*(.*)', GSM8K[i]['answer'])\n","            if NRoutput[i]['final_output']:\n","                model_answer = re.findall(r'<Answer>\\s*(.*?)(?:</Answer>|$)', NRoutput[i]['final_output'], re.DOTALL)\n","            else:\n","                model_answer = []\n","\n","            is_correct = False\n","            if answer and model_answer:\n","                model_answer[0] = model_answer[0].replace(\",\", \"\")\n","                answer[0] = answer[0].replace(\",\", \"\")\n","                if answer[0] in model_answer[0]:\n","                    is_correct = True\n","            if is_correct == False:\n","              model_answer = []\n","              if NRoutput[i]['resets'] == 0:\n","                for msg in NRoutput[i]['chat_history']:\n","                  if msg['role'] == 'assistant':\n","                    matches = re.findall(r'<Answer>(.*?)(?:<\\/Answer>|$)', msg['content'], flags=re.DOTALL)\n","                    model_answer.extend([m.strip() for m in matches])\n","                    for ans in model_answer:\n","                      ans = ans.replace(\",\", \"\")\n","                      if answer[0] in ans:\n","                        print(\"Now correct: \")\n","\n","\n","            corr.append(1 if is_correct else 0)\n","            NRoutput[i]['correct'] = is_correct\n","\n","        with open(data_path + f\"_run{x}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(NRoutput, f_out, indent=2)\n","\n","        correct.append(corr)\n","\n","    sums = 0\n","    for i in range(len(correct)):\n","      print(f\"Run {i} Score: {np.sum(correct[i])/numQ}\")\n","      sums += np.sum(correct[i]) / numQ\n","\n","    print(f\"Average {sums / len(correct)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgVmqHLza5tH"},"outputs":[],"source":["import json\n","import re\n","\n","def Eval_GSM8K(numruns, data_path, numQ=50, dataset=GSM8K):\n","    correct = []\n","    for x in range(numruns):\n","        corr = []\n","        with open(data_path + f\"_run{x}.json\", 'r') as f:\n","            NRoutput = json.load(f)\n","\n","        for i in range(numQ):\n","            answer = re.findall(r'####\\s*(.*)', GSM8K[i]['answer'])\n","            if NRoutput[i]['final_output']:\n","                model_answer = re.findall(r'<Answer>\\s*(.*?)(?:</Answer>|$)', NRoutput[i]['final_output'], re.DOTALL)\n","            else:\n","                model_answer = []\n","\n","            is_correct = False\n","            if answer and model_answer:\n","                model_answer[0] = model_answer[0].replace(\",\", \"\")\n","                answer[0] = answer[0].replace(\",\", \"\")\n","                if answer[0] in model_answer[0]:\n","                    is_correct = True\n","            if is_correct == False:\n","              model_answer = []\n","              assistant_blocks = re.findall(r'<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)(?=<\\|eot_id\\|>)', NRoutput[i]['chat_history'], flags=re.DOTALL)\n","              if not assistant_blocks:\n","                assistant_blocks = re.findall(r'<\\|im_start\\|>assistant<\\|im_sep\\|>(.*?)(?=<\\|im_end\\|>)', NRoutput[i]['chat_history'], flags=re.DOTALL)\n","              for block in assistant_blocks:\n","                matches = re.findall(r'<Answer>(.*?)(?:<\\/Answer>|$)', block, flags=re.DOTALL)\n","                model_answer.extend([m.strip() for m in matches])\n","\n","              # model_answer = re.findall(r'<\\|start_header_id\\|>assistant<\\|end_header_id\\|>.*?(?:<Answer>(.*?)<\\/Answer>|<Answer>(.*?)$)', NRoutput[i]['chat_history'], re.DOTALL)\n","              for ans in model_answer:\n","                ans = ans.replace(\",\", \"\")\n","                if answer[0] in ans:\n","                    # print(f\"Now deeming correct: {ans}\\n\\nACTUAL:{answer[0]}\\n\\n\")\n","                    is_correct = True\n","\n","            corr.append(1 if is_correct else 0)\n","            NRoutput[i]['correct'] = is_correct\n","\n","        # Write corrected output\n","        with open(data_path + f\"_run{x}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(NRoutput, f_out, indent=2)\n","\n","        correct.append(corr)\n","\n","    sums = 0\n","    for i in range(len(correct)):\n","      print(f\"Run {i} Score: {np.sum(correct[i])/numQ}\")\n","      sums += np.sum(correct[i]) / numQ\n","\n","    print(f\"Average {sums / len(correct)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"nN0rsgSabsr9"},"source":["# API Evaluation"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1750644642521,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"Ymr354ZI5xHB"},"outputs":[],"source":["import json\n","\n","def GPT_API_eval(numruns, numQ, dataset, data_path):\n","\n","    avg = []\n","    for i in range(numruns):\n","        correct_count = 0\n","        with open(data_path + f\"_run{i}.json\") as f:\n","            output = json.load(f)\n","\n","        for x in range(numQ):\n","            raw_model_output = output[x]['final_output']\n","            model_answer = re.findall(r'<Answer>\\s*(.*?)(?:</Answer>|$)', raw_model_output, re.DOTALL)\n","            if model_answer:\n","              raw_model_output = model_answer[0]\n","            mod_ans = extract_function_block(raw_model_output)\n","            mod_ans = clean_function_block(mod_ans)\n","            corr = evaluator_function(predicted_answer=mod_ans, sample=dataset[x])\n","\n","            if \"Failing to parse the predicted answer as an AST\" in corr[\"error\"]:\n","              mod_ans = extract_function_block(f\"[{raw_model_output}]\")\n","              mod_ans = clean_function_block(mod_ans)\n","              corr = evaluator_function(predicted_answer=mod_ans, sample=dataset[x])\n","\n","            is_correct = False\n","            if corr[\"is_correct\"]:\n","                correct_count += 1\n","                is_correct = True\n","            else:\n","                if output[x]['resets'] == 0:\n","                  for entry in output[x]['chat_history']:\n","                    if entry[\"role\"] == \"assistant\":\n","                      for block in extract_all_function_blocks(entry['content']):\n","                          corr = evaluator_function(predicted_answer=block, sample=dataset[x])\n","                          if corr[\"is_correct\"]:\n","                              correct_count += 1\n","                              is_correct = True\n","                              break\n","                      if is_correct:\n","                        break\n","                else:\n","                  for block in extract_all_function_blocks(output[x]['chat_history']):\n","                    corr = evaluator_function(predicted_answer=block, sample=dataset[x])\n","                    if corr[\"is_correct\"]:\n","                        correct_count += 1\n","                        is_correct = True\n","                        break\n","\n","            output[x]['correct'] = is_correct\n","\n","\n","        with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(output, f_out, indent=2)\n","\n","        avg.append(correct_count / numQ)\n","        print(f\"Run {i}: {correct_count/numQ}\")\n","\n","    print(f\"Average Accuracy: {np.mean(avg)}\")"]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1750647171130,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"ZQkI-HA0buy4"},"outputs":[],"source":["import json\n","\n","def API_eval(numruns, numQ, dataset, data_path):\n","\n","    avg = []\n","    for i in range(numruns):\n","        correct_count = 0\n","        with open(data_path + f\"_run{i}.json\") as f:\n","            output = json.load(f)\n","\n","        for x in range(numQ):\n","            raw_model_output = output[x]['final_output']\n","            model_answer = re.findall(r'<Answer>\\s*(.*?)(?:</Answer>|$)', raw_model_output, re.DOTALL)\n","            if model_answer:\n","              raw_model_output = model_answer[0]\n","            mod_ans = extract_function_block(raw_model_output)\n","            mod_ans = clean_function_block(mod_ans)\n","            corr = evaluator_function(predicted_answer=mod_ans, sample=dataset[x])\n","\n","            if \"Failing to parse the predicted answer as an AST\" in corr[\"error\"]:\n","              mod_ans = extract_function_block(f\"[{raw_model_output}]\")\n","              mod_ans = clean_function_block(mod_ans)\n","              corr = evaluator_function(predicted_answer=mod_ans, sample=dataset[x])\n","\n","            is_correct = False\n","            if corr[\"is_correct\"]:\n","                correct_count += 1\n","                is_correct = True\n","            else:\n","                for block in extract_all_function_blocks(output[x]['chat_history']):\n","                    corr = evaluator_function(predicted_answer=block, sample=dataset[x])\n","                    if corr[\"is_correct\"]:\n","                        correct_count += 1\n","                        is_correct = True\n","                        break\n","\n","            output[x]['correct'] = is_correct\n","\n","\n","        with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","            json.dump(output, f_out, indent=2)\n","\n","        avg.append(correct_count / numQ)\n","        print(f\"Run {i}: {correct_count/numQ}\")\n","\n","    print(f\"Average Accuracy: {np.mean(avg)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"4In0Rf-aarYH"},"source":["# Database Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLAiUMplatku"},"outputs":[],"source":["import os\n","import json\n","import sqlite3\n","import numpy as np\n","from glob import glob\n","from tqdm import tqdm\n","\n","\n","def DB_eval(dataset, numruns, numQ, data_path):\n","  DB_FOLDER    = '/content/drive/My Drive/Context_reset/DATABASE/DATABASE_PHI-4/spider/database/'                  # folder containing *.sqlite\n","  avg = []\n","  def run_query(db_path, sql):\n","      conn = sqlite3.connect(db_path)\n","      conn.text_factory = lambda b: b.decode('utf-8', errors='replace')\n","      cur  = conn.cursor()\n","      try:\n","          cur.execute(sql)\n","          rows = cur.fetchall()\n","      finally:\n","          conn.close()\n","      return rows\n","\n","  for i in range(numruns):\n","    with open(data_path + f\"_run{i}.json\", 'r') as f:\n","      entries = json.load(f)\n","    correct = 0\n","    res = []\n","    for e in range(numQ):\n","        mismatches = False\n","        db_id     = dataset[e]['db_id']\n","        ref_sql   = dataset[e]['reference_sql']\n","\n","        for llm_sql in extract_sql_queries(entries[e]['final_output']):\n","\n","          db_path = os.path.join(DB_FOLDER, f\"{db_id}/{db_id}.sqlite\")\n","\n","          ref_res = run_query(db_path, ref_sql)\n","          try:\n","              llm_res = run_query(db_path, llm_sql)\n","          except Exception as ex:\n","              mismatches = True\n","              continue\n","\n","          if ref_res != llm_res:\n","              mismatches = True\n","          else:\n","              mismatches = False\n","              break\n","\n","        if mismatches == True:\n","          mismatches = False\n","          for llm_sql in extract_sql_queries(entries[e]['chat_history']):\n","            try:\n","              llm_res = run_query(db_path, llm_sql)\n","            except Exception as ex:\n","              mismatches = True\n","              continue\n","\n","            if ref_res != llm_res:\n","              mismatches = True\n","\n","            if mismatches == False:\n","              break\n","\n","        if mismatches == False:\n","          correct += 1\n","          entries[e]['correct'] = True\n","        else:\n","          entries[e]['correct'] = False\n","\n","        res.append(entries[e]['resets'])\n","\n","    avg.append(correct / numQ)\n","    print(f\"Accuracy = {correct / numQ}\")\n","\n","    with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","      json.dump(entries, f_out, indent=2)\n","\n","  print(f\"Average = {np.mean(avg)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68lhilw5Zhff"},"outputs":[],"source":["import os\n","import json\n","import sqlite3\n","import numpy as np\n","from glob import glob\n","from tqdm import tqdm\n","\n","\n","def GPT_DB_eval(dataset, numruns, numQ, data_path):\n","  DB_FOLDER    = '/content/drive/My Drive/Context_reset/DATABASE/DATABASE_PHI-4/spider/database/'\n","  avg = []\n","  def run_query(db_path, sql):\n","      conn = sqlite3.connect(db_path)\n","      # decode any bytes with replacement on errors\n","      conn.text_factory = lambda b: b.decode('utf-8', errors='replace')\n","      cur  = conn.cursor()\n","      try:\n","          cur.execute(sql)\n","          rows = cur.fetchall()\n","      finally:\n","          conn.close()\n","      return rows\n","\n","  for i in range(numruns):\n","    with open(data_path + f\"_run{i}.json\", 'r') as f:\n","      entries = json.load(f)\n","    correct = 0\n","    res = []\n","    for e in range(numQ):\n","        mismatches = False\n","        db_id     = dataset[e]['db_id']\n","        ref_sql   = dataset[e]['reference_sql']\n","\n","        for llm_sql in extract_sql_queries(entries[e]['final_output']):\n","\n","          db_path = os.path.join(DB_FOLDER, f\"{db_id}/{db_id}.sqlite\")\n","\n","          ref_res = run_query(db_path, ref_sql)\n","          try:\n","              llm_res = run_query(db_path, llm_sql)\n","          except Exception as ex:\n","              mismatches = True\n","              continue\n","\n","          if ref_res != llm_res:\n","              mismatches = True\n","          else:\n","              mismatches = False\n","              break\n","\n","        if mismatches == True:\n","          mismatches = False\n","\n","          if entries[e][\"resets\"] == 0:\n","            for entry in entries[e]['chat_history']:\n","              if entry[\"role\"] == \"assistant\":\n","                for llm_sql in extract_sql_queries(entry['content']):\n","                  try:\n","                    llm_res = run_query(db_path, llm_sql)\n","                  except Exception as ex:\n","                    mismatches = True\n","                    continue\n","\n","                  if ref_res != llm_res:\n","                    mismatches = True\n","\n","                  if mismatches == False:\n","                    break\n","              if mismatches == False:\n","                break\n","          else:\n","            mismatches = False\n","            for llm_sql in extract_sql_queries(entries[e]['chat_history']):\n","              try:\n","                llm_res = run_query(db_path, llm_sql)\n","              except Exception as ex:\n","                mismatches = True\n","                continue\n","\n","              if ref_res != llm_res:\n","                print(ref_res, \"\\n\", llm_res, \"\\n\\n\")\n","                mismatches = True\n","\n","              if mismatches == False:\n","                break\n","\n","        if mismatches == False:\n","          correct += 1\n","          entries[e]['correct'] = True\n","        else:\n","          entries[e]['correct'] = False\n","\n","        res.append(entries[e]['resets'])\n","\n","    avg.append(correct / numQ)\n","    print(f\"Accuracy = {correct / numQ}\")\n","\n","    with open(data_path + f\"_run{i}_CORRECTED.json\", \"w\") as f_out:\n","      json.dump(entries, f_out, indent=2)\n","\n","  print(f\"Average = {np.mean(avg)}\")"]},{"cell_type":"markdown","metadata":{"id":"urmo9Tf_-Gzl"},"source":["# D2T Evaluation"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1750645967308,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"UsgGqHOd-Iq2"},"outputs":[],"source":["def D2T_Eval(numruns, numQ, data_path, dataset):\n","  scores = []\n","  for x in range(numruns):\n","      score = []\n","      with open(data_path + f\"_run{x}.json\", 'r') as f:\n","          outputs = json.load(f)\n","\n","      for i in range(numQ):\n","        curr_score = D2T_evaluator_function(outputs[i]['final_output'], dataset[i])\n","\n","        score.append(curr_score)\n","\n","        outputs[i][\"score\"] = curr_score\n","      with open(data_path + f\"_run{x}_CORRECTED.json\", \"w\") as f_out:\n","          json.dump(outputs, f_out, indent=2)\n","\n","      scores.append(score)\n","\n","  for score in scores:\n","    print(f\"Average: {round(np.mean(score),2)}\")\n","\n","  return scores"]},{"cell_type":"markdown","metadata":{"id":"tvNlda_lmhAq"},"source":["# Calculating Aptitude and Unreliability"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1750645204150,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"GyYiyd1EmiJK"},"outputs":[],"source":["def get_scores(modelname, numruns, numQ):\n","    datasets = ['CODING', 'GSM8K', 'API', 'DB', 'D2T']\n","    correct = {name: [] for name in datasets}\n","    resetNum = 0\n","    \n","    file_configs = {\n","        'LLAMA': {\n","            'CODING': f\"CODING/CODING_{modelname.upper()}/CODING_0.03_run\",\n","            'GSM8K': f\"MATH/MATH_{modelname.upper()}/GSM8K_0.03_run\",\n","            'API': f\"APIs/APIs_{modelname.upper()}/API_0.03_run\",\n","            'DB': f\"DATABASE/DATABASE_{modelname.upper()}/DB_0.03_run\",\n","            'D2T': f\"D2T/D2T_{modelname.upper()}/D2T_0.03_run\"\n","        }\n","    }\n","    \n","    default_config = {\n","        'CODING': f\"CODING/CODING_{modelname}/Code_run\",\n","        'GSM8K': f\"MATH/MATH_{modelname}/GSM8K_run\",\n","        'API': f\"APIs/APIs_{modelname}/API_run\",\n","        'DB': f\"DATABASE/DATABASE_{modelname}/DB_run\",\n","        'D2T': f\"D2T/D2T_{modelname}/D2T_run\"\n","    }\n","    \n","    config = file_configs.get(modelname, default_config)\n","    \n","    for run in range(numruns):\n","        for name in datasets:\n","            file_path = f\"/content/drive/My Drive/Context_reset/{config[name]}{run}_CORRECTED.json\"\n","            \n","            with open(file_path) as f:\n","                data = json.load(f)[:50 if name == 'D2T' else numQ]\n","            \n","            temp_arr = []\n","            for entry in data:\n","                resetNum += entry['resets']\n","                score = entry['score'] if name == 'D2T' else (1 if entry['correct'] else 0)\n","                temp_arr.append(score if score else 0)\n","            \n","            correct[name].append(np.array(temp_arr).T)\n","    \n","    return correct, resetNum"]},{"cell_type":"markdown","metadata":{"id":"CyiDrZMbJ0MX"},"source":["## Aptitude & Reliability"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1750647066394,"user":{"displayName":"HMK","userId":"16235041692412471169"},"user_tz":-240},"id":"qSvWm-kZKCTj"},"outputs":[],"source":["def calculate_aptitude_and_unreliability(runs):\n","    \"\"\"\n","    Calculate aptitude and unreliability for each dataset, then average across datasets.\n","    Pass 'correct' array returned by 'get_scores' function\n","    \"\"\"\n","    \n","    dataset_aptitudes = []\n","    dataset_unreliabilities = []\n","    detailed_results = {}\n","    \n","    for dataset_name, dataset_runs in runs.items():\n","        runs_array = np.array(dataset_runs)\n","        runs_transposed = runs_array.T\n","        \n","        question_aptitudes = np.percentile(runs_transposed, 90, axis=1)\n","        \n","        question_unreliabilities = (np.percentile(runs_transposed, 90, axis=1) - \n","                                  np.percentile(runs_transposed, 10, axis=1))\n","        \n","        dataset_aptitude = np.mean(question_aptitudes)\n","        dataset_unreliability = np.mean(question_unreliabilities)\n","        \n","        dataset_aptitudes.append(dataset_aptitude)\n","        dataset_unreliabilities.append(dataset_unreliability)\n","    \n","    overall_aptitude = np.mean(dataset_aptitudes)\n","    overall_unreliability = np.mean(dataset_unreliabilities)\n","    \n","    print(\"OVERALL RESULTS:\")\n","    print(f\"Average Aptitude: {overall_aptitude:.4f}\")\n","    print(f\"Average Unreliability: {overall_unreliability:.4f}\")\n","    \n","    return overall_aptitude, overall_unreliability, detailed_results"]}],"metadata":{"colab":{"collapsed_sections":["YnldQj6j38cP","3VGX8_24acA-","I1C8ebkE-q6s","tvNlda_lmhAq"],"provenance":[{"file_id":"1sh0lbQ7LWqMFVHPb9mrywIcRGuThqku-","timestamp":1748807084273}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
