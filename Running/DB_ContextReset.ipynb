{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1sh0lbQ7LWqMFVHPb9mrywIcRGuThqku-","timestamp":1748807084273}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Load Model, Dataset"],"metadata":{"id":"YnldQj6j38cP"}},{"cell_type":"code","source":["from google.colab import drive\n","import json\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EsGHBhlWK0l","executionInfo":{"status":"ok","timestamp":1750510942691,"user_tz":-240,"elapsed":19502,"user":{"displayName":"HMK","userId":"16235041692412471169"}},"outputId":"e3093502-97f6-4aea-eec2-394f4822c745"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["with open(\"/content/drive/My Drive/sharded_dataset.json\") as f:\n","  data = json.load(f)"],"metadata":{"id":"PsQP-SzxWOCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DB = []\n","for task in data:\n","  if \"database\" in task['task']:\n","    DB.append(task)"],"metadata":{"id":"gmB_2ey5wVmO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# OPENAI CODE"],"metadata":{"id":"JZwBWp5SV1U7"}},{"cell_type":"code","source":["from openai import OpenAI\n","import math\n","\n","def predictive_entropy_uncertainty_chat(prompt,\n","                                         temperature=1.0,\n","                                         max_tokens = 500,\n","                                         logprobs= True):\n","    \"\"\"\n","    Send `prompt` to OpenAI Completion API, return average token entropy and generated text.\n","    Entropy is approximated from top `logprobs` returned per token.\n","    \"\"\"\n","\n","    client = OpenAI(api_key=\"FILLER\")\n","    resp = client.chat.completions.create(\n","        model=\"gpt-4.1\",\n","        messages=prompt,\n","        max_completion_tokens=max_tokens,\n","        temperature=temperature,\n","        logprobs=logprobs,\n","        top_logprobs = 20,\n","    )\n","\n","    generated_tokens = resp.choices[0].message.content\n","    lps = resp.choices[0].logprobs.content\n","\n","    entropies = []\n","\n","    for token_info in lps:\n","        entropy = 0.0\n","        for alt in token_info.top_logprobs:\n","            p = math.exp(alt.logprob)\n","            entropy += -p * alt.logprob\n","        entropies.append(entropy)\n","\n","    avg_entropy = sum(entropies) / len(entropies) if entropies else 0.0\n","\n","    tokens_used = resp.usage.completion_tokens + resp.usage.prompt_tokens\n","\n","    return avg_entropy, generated_tokens, tokens_used"],"metadata":{"id":"4G6rcQ1NV2uJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import os\n","\n","def prompt_rewrite(prompt):\n","\n","  new_prompt = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a prompt rewriter whose main goal is to rewrite the prompt given by the user in the most optimal way without losing any information in them.\"\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": (\n","            \"I have a set of questions and/or statements, please REWRITE all the questions/statements so that they are in the most optimal order that is the easiest to understand. DO NOT ANSWER ANY OF THE QUESTIONS JUST REWRITE. Here are the instructions:\\n\"\n","            \"Write SQL query to find active users\"\n","            \"active users are those who made at least 5 purchases\"\n","            \"each purchase is in the purchases table\"\n","            \"users are in the users table\"\n","            \"return user names only\"\n","        )\n","    },\n","    {\n","        \"role\": \"assistant\",\n","        \"content\": \"Write an SQL query to find the names of users who have made at least 5 purchases, using the users and purchases tables.\"\n","    },\n","]\n","\n","  user_content = \"I have a set of questions and/or statements, please REWRITE all the questions/statements so that they are in the most optimal order that is the easiest to understand. DO NOT ANSWER ANY OF THE QUESTIONS JUST REWRITE. Here are the instructions:\\n\"\n","  user_messages = [item[\"content\"] for item in prompt if item.get(\"role\") == \"user\"]\n","  for msg in user_messages:\n","    user_content += msg + \"\\n\"\n","\n","  new_prompt.append({\"role\": \"user\", \"content\": user_content})\n","\n","  return new_prompt"],"metadata":{"id":"qvmMc3fDV8Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def with_context_reset_chat(dataset, file_path, threshold,\n","                            temperature=1.0, runs=1, numQ=50):\n","\n","    connectors = [\"oh also, \", \"I just remembered, \", \"sorry i forgot to say, \", \"\", \"oh, and \", \"FYI, \"]\n","    tokens_used = 0\n","\n","    for run in range(runs):\n","        print(f\"Run {run+1}/{runs}\")\n","        out_path = file_path.replace(\".json\", f\"_run{run}.json\")\n","        results = []\n","\n","        for entry in dataset:\n","            base_system = {\n","        \"role\": \"system\",\n","        \"content\": (\n","            f\"\"\"\\nYou are helping a user write SQL queries to a database. If something is not clear, you can ask the user to clarify what they need. The schema for the database being accessed is the following:\\n{entry['schema_sql']}\"\"\"\n","        )\n","    }\n","            shards = entry[\"shards\"]\n","            print(f\"Question with {len(shards)} shards\")\n","            messages = [base_system]\n","            prev_entropy = float(\"inf\")\n","            resets = 0\n","            entropies = []\n","            before_reset = None\n","            choice = random.choice(connectors)\n","\n","            for shard in shards:\n","                user_content = shard[\"shard\"]\n","                if shard['shard_id'] != 1:\n","                  user_content = choice + user_content\n","                if shard[\"shard_id\"] == len(shards):\n","                    user_content += \" Please include your complete new Query in your response.\"\n","                messages.append({\"role\": \"user\", \"content\": user_content})\n","\n","                entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=1.0, logprobs=True)\n","                print(f\"Entropy: {entropy:.4f}\")\n","                tokens_used += tok\n","\n","                if entropy - prev_entropy > threshold:\n","                    before_reset = list(messages)\n","                    messages = prompt_rewrite(messages)\n","                    entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=0.2, logprobs=True)\n","                    tokens_used += tok\n","                    messages = [base_system, {\"role\": \"user\", \"content\": reply}]\n","                    entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=1.0, logprobs=True)\n","                    print(f\"Reset entropy: {entropy:.4f}\")\n","                    tokens_used += tok\n","                    resets += 1\n","\n","                prev_entropy = entropy\n","                entropies.append(entropy)\n","                messages.append({\"role\": \"assistant\", \"content\": reply})\n","\n","                print(f\"Current Tokens Used: {tokens_used}\")\n","\n","                if shard[\"shard_id\"] == len(entry[\"shards\"]):\n","\n","                  if before_reset:\n","                    chat_history = f\"{before_reset}\\n\\nAFTER RESET\\n\\n{messages}\"\n","                  else:\n","                    chat_history = messages\n","\n","                  new_entry = {\"final_output\": reply, \"chat_history\": chat_history, \"entropies\": entropies, \"resets\":resets}\n","\n","                  if os.path.exists(out_path):\n","                    with open(out_path, \"r\") as f:\n","                        data = json.load(f)\n","                  else:\n","                      data = []\n","\n","                  data.append(new_entry)\n","\n","                  with open(out_path, \"w\") as f:\n","                      json.dump(data, f, indent=2)"],"metadata":{"id":"kS2xRPeDWJcu"},"execution_count":null,"outputs":[]}]}