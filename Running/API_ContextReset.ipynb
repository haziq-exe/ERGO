{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1sh0lbQ7LWqMFVHPb9mrywIcRGuThqku-","timestamp":1748807084273}],"collapsed_sections":["yGkNtNQsxae7"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Load Model, Dataset"],"metadata":{"id":"YnldQj6j38cP"}},{"cell_type":"code","source":["from google.colab import drive\n","import json\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EsGHBhlWK0l","executionInfo":{"status":"ok","timestamp":1750507518381,"user_tz":-240,"elapsed":21572,"user":{"displayName":"HMK","userId":"16235041692412471169"}},"outputId":"47c458e3-b3b3-46bd-890f-3b3810f0291a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["with open(\"/content/drive/My Drive/sharded_dataset.json\") as f:\n","  data = json.load(f)"],"metadata":{"id":"PsQP-SzxWOCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["API = []\n","for task in data:\n","  if \"actions\" in task['task']:\n","    API.append(task)"],"metadata":{"id":"gmB_2ey5wVmO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# OPENAI CODE"],"metadata":{"id":"yGkNtNQsxae7"}},{"cell_type":"code","source":["from openai import OpenAI\n","import math\n","\n","def predictive_entropy_uncertainty_chat(prompt,\n","                                         temperature=1.0,\n","                                         max_tokens = 500,\n","                                         logprobs= True):\n","    \"\"\"\n","    Send `prompt` to OpenAI Completion API, return average token entropy and generated text.\n","    Entropy is approximated from top `logprobs` returned per token.\n","    \"\"\"\n","\n","    client = OpenAI(api_key=\"FILLER\")\n","    resp = client.chat.completions.create(\n","        model=\"gpt-4.1\",\n","        messages=prompt,\n","        max_completion_tokens=max_tokens,\n","        temperature=temperature,\n","        logprobs=logprobs,\n","        top_logprobs = 20,\n","    )\n","\n","    generated_tokens = resp.choices[0].message.content\n","    lps = resp.choices[0].logprobs.content\n","\n","    entropies = []\n","\n","    for token_info in lps:\n","        entropy = 0.0\n","        for alt in token_info.top_logprobs:\n","            p = math.exp(alt.logprob)\n","            entropy += -p * alt.logprob\n","        entropies.append(entropy)\n","\n","    avg_entropy = sum(entropies) / len(entropies) if entropies else 0.0\n","\n","    tokens_used = resp.usage.completion_tokens + resp.usage.prompt_tokens\n","\n","    return avg_entropy, generated_tokens, tokens_used"],"metadata":{"id":"-6gR7c1bxjNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import os\n","\n","def prompt_rewrite(prompt):\n","\n","  new_prompt = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a prompt rewriter whose main goal is to rewrite the prompt given by the user in the most optimal way without losing any information in them.\"\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": (\n","            \"I have a set of questions and/or statements, please REWRITE all the questions/statements so that they are in the most optimal order that is the easiest to understand. DO NOT ANSWER ANY OF THE QUESTIONS JUST REWRITE. Here are the instructions:\\n\"\n","            \"how much will John pay in sales tax?\\n\"\n","            \"the purchase amount is $120\\n\"\n","            \"the sales tax rate is 8.25%.\"\n","        )\n","    },\n","    {\n","        \"role\": \"assistant\",\n","        \"content\": \"What is the total sales tax John will pay on a $120 purchase at an 8.25% rate?\"\n","    },\n","]\n","\n","  user_content = \"I have a set of questions and/or statements, please REWRITE all the questions/statements so that they are in the most optimal order that is the easiest to understand. DO NOT ANSWER ANY OF THE QUESTIONS JUST REWRITE. Here are the instructions:\\n\"\n","  user_messages = [item[\"content\"] for item in prompt if item.get(\"role\") == \"user\"]\n","  for msg in user_messages:\n","    user_content += msg + \"\\n\"\n","\n","  new_prompt.append({\"role\": \"user\", \"content\": user_content})\n","\n","  return new_prompt"],"metadata":{"id":"aqBnw2QOxcS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def with_context_reset_chat(dataset, file_path, threshold,\n","                            temperature=1.0, runs=1, numQ=50):\n","\n","    connectors = [\"oh also, \", \"I just remembered, \", \"sorry i forgot to say, \", \"\", \"oh, and \", \"FYI, \"]\n","    tokens_used = 0\n","\n","    for run in range(runs):\n","        print(f\"Run {run+1}/{runs}\")\n","        out_path = file_path.replace(\".json\", f\"_run{run}.json\")\n","        results = []\n","\n","        for entry in dataset:\n","            base_system = {\n","        \"role\": \"system\",\n","        \"content\": (\n","            f\"\"\"You are an expert in composing functions. You are given a question and a set of possible functions. Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\n","If none of the functions can be used, point it out. If the given question lacks the parameters required by the function, also point it out.\n","You should only return the function calls in your response.\n","\n","If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n","You SHOULD NOT include any other text in the response.\n","\n","At each turn, you should try your best to complete the tasks requested by the user within the current turn. Continue to output functions to call until you have fulfilled the user's request to the best of your ability. Once you have no more functions to call, the system will consider the current turn complete and proceed to the next turn or task.\n","\n","Here is a list of functions in JSON format that you can invoke.\n","\n","{entry['function']}\"\"\"\n","        )\n","    }\n","            shards = entry[\"shards\"]\n","            print(f\"Question with {len(shards)} shards\")\n","            messages = [base_system]\n","            prev_entropy = float(\"inf\")\n","            resets = 0\n","            entropies = []\n","            before_reset = None\n","            choice = random.choice(connectors)\n","\n","            for shard in shards:\n","                user_content = shard[\"shard\"]\n","                if shard['shard_id'] != 1:\n","                  user_content = choice + user_content\n","                if shard[\"shard_id\"] == len(shards):\n","                    user_content += \" Please include all the functions neccessary to complete my task in your response.\"\n","                messages.append({\"role\": \"user\", \"content\": user_content})\n","\n","                entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=1.0, logprobs=True)\n","                print(f\"Entropy: {entropy:.4f}\")\n","                tokens_used += tok\n","\n","                if entropy - prev_entropy > threshold:\n","                    before_reset = list(messages)\n","                    messages = prompt_rewrite(messages)\n","                    entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=0.2, logprobs=True)\n","                    tokens_used += tok\n","                    messages = [base_system, {\"role\": \"user\", \"content\": reply}]\n","                    entropy, reply, tok = predictive_entropy_uncertainty_chat(messages, temperature=1.0, logprobs=True)\n","                    print(f\"Reset entropy: {entropy:.4f}\")\n","                    tokens_used += tok\n","                    resets += 1\n","\n","                prev_entropy = entropy\n","                entropies.append(entropy)\n","                messages.append({\"role\": \"assistant\", \"content\": reply})\n","\n","                print(f\"Current Tokens Used: {tokens_used}\")\n","\n","                if shard[\"shard_id\"] == len(entry[\"shards\"]):\n","\n","                  if before_reset:\n","                    chat_history = f\"{before_reset}\\n\\nAFTER RESET\\n\\n{messages}\"\n","                  else:\n","                    chat_history = messages\n","\n","                  new_entry = {\"final_output\": reply, \"chat_history\": chat_history, \"entropies\": entropies, \"resets\":resets}\n","\n","                  if os.path.exists(out_path):\n","                    with open(out_path, \"r\") as f:\n","                        data = json.load(f)\n","                  else:\n","                      data = []\n","\n","                  data.append(new_entry)\n","\n","                  with open(out_path, \"w\") as f:\n","                      json.dump(data, f, indent=2)"],"metadata":{"id":"Tz3v4hm1xmxh"},"execution_count":null,"outputs":[]}]}